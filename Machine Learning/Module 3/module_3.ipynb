{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4418cae4",
   "metadata": {},
   "source": [
    "# Module 3: Scaling, Encoding, and Distance Measures\n",
    "\n",
    "This notebook covers:\n",
    "1. **Standardization (Z-score Scaling)**\n",
    "2. **Min-Max Scaling**\n",
    "3. **Robust Scaling**\n",
    "4. **One-Hot Encoding (Nominal)**\n",
    "5. **Ordinal Encoding**\n",
    "6. **Euclidean and Manhattan Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5481295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d244a",
   "metadata": {},
   "source": [
    "## 1. Standardization (Z-score Scaling)\n",
    "\n",
    "**Formula:** $z = \\frac{x - \\mu}{\\sigma}$\n",
    "\n",
    "Where:\n",
    "- $x$ = original value\n",
    "- $\\mu$ = mean\n",
    "- $\\sigma$ = standard deviation\n",
    "\n",
    "This transforms data to have mean = 0 and standard deviation = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637ff59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "  Person  Height (cm)  Weight (Kg)\n",
      "0      A          150           50\n",
      "1      B          160           60\n",
      "2      C          170           70\n",
      "3      D          180           80\n",
      "4      E          190           90\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create dataset for Standardization\n",
    "data_standard = {\n",
    "    'Person': ['A', 'B', 'C', 'D', 'E'],\n",
    "    'Height (cm)': [150, 160, 170, 180, 190],\n",
    "    'Weight (Kg)': [50, 60, 70, 80, 90]\n",
    "}\n",
    "\n",
    "df_standard = pd.DataFrame(data_standard)\n",
    "print(\"Original Data:\")\n",
    "print(df_standard)\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e9621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height Statistics:\n",
      "Mean (μ): 170.0\n",
      "Standard Deviation (σ): 14.1421\n",
      "\n",
      "Manual Z-score Calculation for Height:\n",
      "Height 150: z = (150 - 170.0) / 14.1421 = -1.4142\n",
      "Height 160: z = (160 - 170.0) / 14.1421 = -0.7071\n",
      "Height 170: z = (170 - 170.0) / 14.1421 = 0.0000\n",
      "Height 180: z = (180 - 170.0) / 14.1421 = 0.7071\n",
      "Height 190: z = (190 - 170.0) / 14.1421 = 1.4142\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Manual Calculation for Height\n",
    "heights = df_standard['Height (cm)'].values\n",
    "mean_height = np.mean(heights)\n",
    "std_height = np.std(heights, ddof=0)  # Population std\n",
    "\n",
    "print(f\"Height Statistics:\")\n",
    "print(f\"Mean (μ): {mean_height}\")\n",
    "print(f\"Standard Deviation (σ): {std_height:.4f}\")\n",
    "print(\"\\nManual Z-score Calculation for Height:\")\n",
    "\n",
    "z_scores_height_manual = []\n",
    "for h in heights:\n",
    "    z = (h - mean_height) / std_height\n",
    "    z_scores_height_manual.append(z)\n",
    "    print(f\"Height {h}: z = ({h} - {mean_height}) / {std_height:.4f} = {z:.4f}\")\n",
    "\n",
    "df_standard['Height_Z_Manual'] = z_scores_height_manual\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c9f53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Data (Z-scores):\n",
      "  Person  Height (cm)  Weight (Kg)  Height_Z_Manual  Height_Z_Score  \\\n",
      "0      A          150           50        -1.414214       -1.414214   \n",
      "1      B          160           60        -0.707107       -0.707107   \n",
      "2      C          170           70         0.000000        0.000000   \n",
      "3      D          180           80         0.707107        0.707107   \n",
      "4      E          190           90         1.414214        1.414214   \n",
      "\n",
      "   Weight_Z_Score  \n",
      "0       -1.414214  \n",
      "1       -0.707107  \n",
      "2        0.000000  \n",
      "3        0.707107  \n",
      "4        1.414214  \n",
      "\n",
      "============================================================\n",
      "\n",
      "Verification - Height Z-scores:\n",
      "Mean: 0.0000000000 (should be ~0)\n",
      "Std Dev: 1.0000000000 (should be 1)\n"
     ]
    }
   ],
   "source": [
    "# Using sklearn StandardScaler\n",
    "scaler_standard = StandardScaler()\n",
    "scaled_values = scaler_standard.fit_transform(df_standard[['Height (cm)', 'Weight (Kg)']])\n",
    "\n",
    "df_standard['Height_Z_Score'] = scaled_values[:, 0]\n",
    "df_standard['Weight_Z_Score'] = scaled_values[:, 1]\n",
    "\n",
    "print(\"Standardized Data (Z-scores):\")\n",
    "print(df_standard)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"\\nVerification - Height Z-scores:\")\n",
    "print(f\"Mean: {df_standard['Height_Z_Score'].mean():.10f} (should be ~0)\")\n",
    "print(f\"Std Dev: {df_standard['Height_Z_Score'].std(ddof=0):.10f} (should be 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908fd372",
   "metadata": {},
   "source": [
    "## 2. Min-Max Scaling (Rescaling to [0, 1])\n",
    "\n",
    "**Formula:** $x' = \\frac{x - x_{min}}{x_{max} - x_{min}}$\n",
    "\n",
    "Where:\n",
    "- $x$ = original value\n",
    "- $x_{min}$ = minimum value in the feature\n",
    "- $x_{max}$ = maximum value in the feature\n",
    "\n",
    "This transforms data to range [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc229e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "  Person  Height (cm)  Weight (Kg)\n",
      "0      A          150           50\n",
      "1      B          160           60\n",
      "2      C          170           70\n",
      "3      D          180           80\n",
      "4      E          190           90\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create dataset for Min-Max Scaling\n",
    "data_minmax = {\n",
    "    'Person': ['A', 'B', 'C', 'D', 'E'],\n",
    "    'Height (cm)': [150, 160, 170, 180, 190],\n",
    "    'Weight (Kg)': [50, 60, 70, 80, 90]\n",
    "}\n",
    "\n",
    "df_minmax = pd.DataFrame(data_minmax)\n",
    "print(\"Original Data:\")\n",
    "print(df_minmax)\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974efc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Statistics:\n",
      "Min (x_min): 50\n",
      "Max (x_max): 90\n",
      "\n",
      "Manual Min-Max Scaling Calculation for Weight:\n",
      "Weight 50: x' = (50 - 50) / (90 - 50) = 0.0000\n",
      "Weight 60: x' = (60 - 50) / (90 - 50) = 0.2500\n",
      "Weight 70: x' = (70 - 50) / (90 - 50) = 0.5000\n",
      "Weight 80: x' = (80 - 50) / (90 - 50) = 0.7500\n",
      "Weight 90: x' = (90 - 50) / (90 - 50) = 1.0000\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Manual Calculation for Weight\n",
    "weights = df_minmax['Weight (Kg)'].values\n",
    "min_weight = np.min(weights)\n",
    "max_weight = np.max(weights)\n",
    "\n",
    "print(f\"Weight Statistics:\")\n",
    "print(f\"Min (x_min): {min_weight}\")\n",
    "print(f\"Max (x_max): {max_weight}\")\n",
    "print(\"\\nManual Min-Max Scaling Calculation for Weight:\")\n",
    "\n",
    "scaled_weights_manual = []\n",
    "for w in weights:\n",
    "    scaled = (w - min_weight) / (max_weight - min_weight)\n",
    "    scaled_weights_manual.append(scaled)\n",
    "    print(f\"Weight {w}: x' = ({w} - {min_weight}) / ({max_weight} - {min_weight}) = {scaled:.4f}\")\n",
    "\n",
    "df_minmax['Weight_Scaled_Manual'] = scaled_weights_manual\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cbf5df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-Max Scaled Data [0, 1]:\n",
      "  Person  Height (cm)  Weight (Kg)  Weight_Scaled_Manual  Height_Scaled  \\\n",
      "0      A          150           50                  0.00           0.00   \n",
      "1      B          160           60                  0.25           0.25   \n",
      "2      C          170           70                  0.50           0.50   \n",
      "3      D          180           80                  0.75           0.75   \n",
      "4      E          190           90                  1.00           1.00   \n",
      "\n",
      "   Weight_Scaled  \n",
      "0           0.00  \n",
      "1           0.25  \n",
      "2           0.50  \n",
      "3           0.75  \n",
      "4           1.00  \n",
      "\n",
      "============================================================\n",
      "\n",
      "Verification - Weight Scaled:\n",
      "Min: 0.0 (should be 0)\n",
      "Max: 1.0 (should be 1)\n"
     ]
    }
   ],
   "source": [
    "# Using sklearn MinMaxScaler\n",
    "scaler_minmax = MinMaxScaler()\n",
    "scaled_values = scaler_minmax.fit_transform(df_minmax[['Height (cm)', 'Weight (Kg)']])\n",
    "\n",
    "df_minmax['Height_Scaled'] = scaled_values[:, 0]\n",
    "df_minmax['Weight_Scaled'] = scaled_values[:, 1]\n",
    "\n",
    "print(\"Min-Max Scaled Data [0, 1]:\")\n",
    "print(df_minmax)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"\\nVerification - Weight Scaled:\")\n",
    "print(f\"Min: {df_minmax['Weight_Scaled'].min()} (should be 0)\")\n",
    "print(f\"Max: {df_minmax['Weight_Scaled'].max()} (should be 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14593461",
   "metadata": {},
   "source": [
    "## 3. Robust Scaling (Outlier-Resistant)\n",
    "\n",
    "**Formula:** $x' = \\frac{x - Q_2}{IQR}$\n",
    "\n",
    "Where:\n",
    "- $x$ = original value\n",
    "- $Q_2$ = median\n",
    "- $IQR = Q_3 - Q_1$ (Interquartile Range)\n",
    "\n",
    "This is resistant to outliers because it uses median and IQR instead of mean and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "326b4b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (with Outliers):\n",
      "  Person  Height (cm)  Weight (Kg)\n",
      "0      A          150           50\n",
      "1      B          160           60\n",
      "2      C          170           70\n",
      "3      D          180           80\n",
      "4      E          300          200\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create dataset with outliers for Robust Scaling\n",
    "data_robust = {\n",
    "    'Person': ['A', 'B', 'C', 'D', 'E'],\n",
    "    'Height (cm)': [150, 160, 170, 180, 300],  # E is outlier\n",
    "    'Weight (Kg)': [50, 60, 70, 80, 200]       # E is outlier\n",
    "}\n",
    "\n",
    "df_robust = pd.DataFrame(data_robust)\n",
    "print(\"Original Data (with Outliers):\")\n",
    "print(df_robust)\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3015397e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Statistics:\n",
      "Q1 (25th percentile): 60.0\n",
      "Q2 (Median, 50th percentile): 70.0\n",
      "Q3 (75th percentile): 80.0\n",
      "IQR (Q3 - Q1): 20.0\n",
      "\n",
      "Manual Robust Scaling Calculation for Weight:\n",
      "Weight 50: x' = (50 - 70.0) / 20.0 = -1.0000\n",
      "Weight 60: x' = (60 - 70.0) / 20.0 = -0.5000\n",
      "Weight 70: x' = (70 - 70.0) / 20.0 = 0.0000\n",
      "Weight 80: x' = (80 - 70.0) / 20.0 = 0.5000\n",
      "Weight 200: x' = (200 - 70.0) / 20.0 = 6.5000\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Manual Calculation for Weight\n",
    "weights_robust = df_robust['Weight (Kg)'].values\n",
    "Q1 = np.percentile(weights_robust, 25)\n",
    "Q2 = np.percentile(weights_robust, 50)  # Median\n",
    "Q3 = np.percentile(weights_robust, 75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(f\"Weight Statistics:\")\n",
    "print(f\"Q1 (25th percentile): {Q1}\")\n",
    "print(f\"Q2 (Median, 50th percentile): {Q2}\")\n",
    "print(f\"Q3 (75th percentile): {Q3}\")\n",
    "print(f\"IQR (Q3 - Q1): {IQR}\")\n",
    "print(\"\\nManual Robust Scaling Calculation for Weight:\")\n",
    "\n",
    "robust_scaled_manual = []\n",
    "for w in weights_robust:\n",
    "    scaled = (w - Q2) / IQR\n",
    "    robust_scaled_manual.append(scaled)\n",
    "    print(f\"Weight {w}: x' = ({w} - {Q2}) / {IQR} = {scaled:.4f}\")\n",
    "\n",
    "df_robust['Weight_Robust_Manual'] = robust_scaled_manual\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac4b7a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robust Scaled Data:\n",
      "  Person  Height (cm)  Weight (Kg)  Weight_Robust_Manual  Height_Robust  \\\n",
      "0      A          150           50                  -1.0           -1.0   \n",
      "1      B          160           60                  -0.5           -0.5   \n",
      "2      C          170           70                   0.0            0.0   \n",
      "3      D          180           80                   0.5            0.5   \n",
      "4      E          300          200                   6.5            6.5   \n",
      "\n",
      "   Weight_Robust  \n",
      "0           -1.0  \n",
      "1           -0.5  \n",
      "2            0.0  \n",
      "3            0.5  \n",
      "4            6.5  \n",
      "\n",
      "============================================================\n",
      "\n",
      "Notice: Outlier (Person E) has less extreme scaled values compared to other methods\n"
     ]
    }
   ],
   "source": [
    "# Using sklearn RobustScaler\n",
    "scaler_robust = RobustScaler()\n",
    "scaled_values = scaler_robust.fit_transform(df_robust[['Height (cm)', 'Weight (Kg)']])\n",
    "\n",
    "df_robust['Height_Robust'] = scaled_values[:, 0]\n",
    "df_robust['Weight_Robust'] = scaled_values[:, 1]\n",
    "\n",
    "print(\"Robust Scaled Data:\")\n",
    "print(df_robust)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nNotice: Outlier (Person E) has less extreme scaled values compared to other methods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fcece5",
   "metadata": {},
   "source": [
    "## 4. Nominal vs Ordinal + One-Hot Encoding\n",
    "\n",
    "### Nominal Features\n",
    "- Categories with **no order**\n",
    "- Example: Color (red, blue, green)\n",
    "- Use: **One-Hot Encoding**\n",
    "\n",
    "### Ordinal Features\n",
    "- Categories with **clear ranking**\n",
    "- Example: Size (Small < Medium < Large)\n",
    "- Use: **Ordinal Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84b24919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tiny Dataset:\n",
      "   id  color    size  price\n",
      "0   1    red   Small     10\n",
      "1   2   blue  Medium     12\n",
      "2   3  green   Large     15\n",
      "3   4    red  Medium     11\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create tiny dataset\n",
    "data_encoding = {\n",
    "    'id': [1, 2, 3, 4],\n",
    "    'color': ['red', 'blue', 'green', 'red'],\n",
    "    'size': ['Small', 'Medium', 'Large', 'Medium'],\n",
    "    'price': [10, 12, 15, 11]\n",
    "}\n",
    "\n",
    "df_encoding = pd.DataFrame(data_encoding)\n",
    "print(\"Original Tiny Dataset:\")\n",
    "print(df_encoding)\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c36086",
   "metadata": {},
   "source": [
    "### One-Hot Encoding for Nominal Feature (Color)\n",
    "\n",
    "**Steps:**\n",
    "1. Create new columns: `Color_red`, `Color_blue`, `Color_green`\n",
    "2. Assign 1 or 0 based on the category\n",
    "3. Row representation:\n",
    "   - id 1: red → [1, 0, 0]\n",
    "   - id 2: blue → [0, 1, 0]\n",
    "   - id 3: green → [0, 0, 1]\n",
    "   - id 4: red → [1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39c6383c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Creating New Columns\n",
      "Columns: Color_red, Color_blue, Color_green\n",
      "\n",
      "Step 2: The Transformed Table:\n",
      "   id  color    size  price  Color_red  Color_blue  Color_green\n",
      "0   1    red   Small     10          1           0            0\n",
      "1   2   blue  Medium     12          0           1            0\n",
      "2   3  green   Large     15          0           0            1\n",
      "3   4    red  Medium     11          1           0            0\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Manual One-Hot Encoding\n",
    "df_onehot = df_encoding.copy()\n",
    "\n",
    "print(\"Step 1: Creating New Columns\")\n",
    "print(\"Columns: Color_red, Color_blue, Color_green\\n\")\n",
    "\n",
    "# Manual assignment\n",
    "df_onehot['Color_red'] = df_onehot['color'].apply(lambda x: 1 if x == 'red' else 0)\n",
    "df_onehot['Color_blue'] = df_onehot['color'].apply(lambda x: 1 if x == 'blue' else 0)\n",
    "df_onehot['Color_green'] = df_onehot['color'].apply(lambda x: 1 if x == 'green' else 0)\n",
    "\n",
    "print(\"Step 2: The Transformed Table:\")\n",
    "print(df_onehot)\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a181dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Row by Row Visualization:\n",
      "id 1: red → [1, 0, 0]\n",
      "id 2: blue → [0, 1, 0]\n",
      "id 3: green → [0, 0, 1]\n",
      "id 4: red → [1, 0, 0]\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Row by Row Visualization\n",
    "print(\"Step 3: Row by Row Visualization:\")\n",
    "for idx, row in df_onehot.iterrows():\n",
    "    vector = [row['Color_red'], row['Color_blue'], row['Color_green']]\n",
    "    print(f\"id {row['id']}: {row['color']} → {vector}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8e54329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pandas get_dummies():\n",
      "   id    size  price  Color_blue  Color_green  Color_red\n",
      "0   1   Small     10       False        False       True\n",
      "1   2  Medium     12        True        False      False\n",
      "2   3   Large     15       False         True      False\n",
      "3   4  Medium     11       False        False       True\n"
     ]
    }
   ],
   "source": [
    "# Using pandas get_dummies\n",
    "df_onehot_pd = pd.get_dummies(df_encoding, columns=['color'], prefix='Color')\n",
    "print(\"Using pandas get_dummies():\")\n",
    "print(df_onehot_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21f573f",
   "metadata": {},
   "source": [
    "## 5. Ordinal Encoding\n",
    "\n",
    "For ordinal features with clear ranking, we assign numerical values based on the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bd619f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Decide Order:\n",
      "Small: 1, Medium: 2, Large: 3\n",
      "\n",
      "============================================================\n",
      "\n",
      "Step 2: The Transformed Table:\n",
      "   id  color    size  price  Size_encode\n",
      "0   1    red   Small     10            1\n",
      "1   2   blue  Medium     12            2\n",
      "2   3  green   Large     15            3\n",
      "3   4    red  Medium     11            2\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Ordinal Encoding for size feature\n",
    "df_ordinal = df_encoding.copy()\n",
    "\n",
    "print(\"Step 1: Decide Order:\")\n",
    "print(\"Small: 1, Medium: 2, Large: 3\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Manual mapping\n",
    "size_mapping = {'Small': 1, 'Medium': 2, 'Large': 3}\n",
    "df_ordinal['Size_encode'] = df_ordinal['size'].map(size_mapping)\n",
    "\n",
    "print(\"\\nStep 2: The Transformed Table:\")\n",
    "print(df_ordinal)\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb0e079c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sklearn OrdinalEncoder:\n",
      "   id    size  Size_encode_sklearn\n",
      "0   1   Small                  0.0\n",
      "1   2  Medium                  1.0\n",
      "2   3   Large                  2.0\n",
      "3   4  Medium                  1.0\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Using sklearn OrdinalEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Small', 'Medium', 'Large']])\n",
    "df_ordinal_sklearn = df_encoding.copy()\n",
    "df_ordinal_sklearn['Size_encode_sklearn'] = ordinal_encoder.fit_transform(df_ordinal_sklearn[['size']])\n",
    "\n",
    "print(\"Using sklearn OrdinalEncoder:\")\n",
    "print(df_ordinal_sklearn[['id', 'size', 'Size_encode_sklearn']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2769e365",
   "metadata": {},
   "source": [
    "## 6. Euclidean Distance & Manhattan Distance\n",
    "\n",
    "### What These Measure\n",
    "- **Euclidean distance:** Straight line closeness (as the crow flies)\n",
    "- **Manhattan distance:** City-block closeness (taxi cab distance)\n",
    "\n",
    "### Formulas\n",
    "For $p = [p_1, p_2, ..., p_k]$ and $q = [q_1, q_2, ..., q_k]$:\n",
    "\n",
    "**Euclidean:** $d_2(p,q) = \\sqrt{\\sum_{i=1}^{k} (p_i - q_i)^2}$\n",
    "\n",
    "**Manhattan:** $d_1(p,q) = \\sum_{i=1}^{k} |p_i - q_i|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3b40410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Data:\n",
      "  Student  Feature1  Feature2\n",
      "0      S1        70        80\n",
      "1      S2        60        90\n",
      "2      S3        85        60\n",
      "3      S4        78        76\n",
      "4      S5        62        65\n",
      "\n",
      "Query Point q = [75, 70]\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Tiny dataset for distance calculation\n",
    "data_distance = {\n",
    "    'Student': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "    'Feature1': [70, 60, 85, 78, 62],\n",
    "    'Feature2': [80, 90, 60, 76, 65]\n",
    "}\n",
    "\n",
    "df_distance = pd.DataFrame(data_distance)\n",
    "print(\"Student Data:\")\n",
    "print(df_distance)\n",
    "print(\"\\nQuery Point q = [75, 70]\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddb3b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Calculation for S1 vs q:\n",
      "============================================================\n",
      "S1 = [70 80]\n",
      "q  = [75 70]\n",
      "\n",
      "Differences:\n",
      "  Feature1: (70 - 75) = -5\n",
      "  Feature2: (80 - 70) = 10\n",
      "\n",
      "Euclidean Distance:\n",
      "  d = sqrt((-5)² + (10)²)\n",
      "  d = sqrt(25 + 100)\n",
      "  d = sqrt(125)\n",
      "  d ≈ 11.180\n",
      "\n",
      "Manhattan Distance:\n",
      "  d = |-5| + |10|\n",
      "  d = 5 + 10\n",
      "  d = 15\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Define query point\n",
    "q = np.array([75, 70])\n",
    "\n",
    "print(\"\\nDetailed Calculation for S1 vs q:\")\n",
    "print(\"=\"*60)\n",
    "S1 = np.array([70, 80])\n",
    "print(f\"S1 = {S1}\")\n",
    "print(f\"q  = {q}\")\n",
    "print(f\"\\nDifferences:\")\n",
    "diff1 = 70 - 75\n",
    "diff2 = 80 - 70\n",
    "print(f\"  Feature1: (70 - 75) = {diff1}\")\n",
    "print(f\"  Feature2: (80 - 70) = {diff2}\")\n",
    "\n",
    "# Euclidean\n",
    "euclidean_s1 = np.sqrt(diff1**2 + diff2**2)\n",
    "print(f\"\\nEuclidean Distance:\")\n",
    "print(f\"  d = sqrt(({diff1})² + ({diff2})²)\")\n",
    "print(f\"  d = sqrt({diff1**2} + {diff2**2})\")\n",
    "print(f\"  d = sqrt({diff1**2 + diff2**2})\")\n",
    "print(f\"  d ≈ {euclidean_s1:.3f}\")\n",
    "\n",
    "# Manhattan\n",
    "manhattan_s1 = abs(diff1) + abs(diff2)\n",
    "print(f\"\\nManhattan Distance:\")\n",
    "print(f\"  d = |{diff1}| + |{diff2}|\")\n",
    "print(f\"  d = {abs(diff1)} + {abs(diff2)}\")\n",
    "print(f\"  d = {manhattan_s1}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b653c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance Calculations for All Students:\n",
      "  Student     Point  Euclidean Distance  Manhattan Distance\n",
      "0      S1  [70, 80]              11.180                  15\n",
      "1      S2  [60, 90]              25.000                  35\n",
      "2      S3  [85, 60]              14.142                  20\n",
      "3      S4  [78, 76]               6.708                   9\n",
      "4      S5  [62, 65]              13.928                  18\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate distances for all students\n",
    "def euclidean_distance(p1, p2):\n",
    "    \"\"\"Calculate Euclidean distance between two points\"\"\"\n",
    "    return np.sqrt(np.sum((p1 - p2)**2))\n",
    "\n",
    "def manhattan_distance(p1, p2):\n",
    "    \"\"\"Calculate Manhattan distance between two points\"\"\"\n",
    "    return np.sum(np.abs(p1 - p2))\n",
    "\n",
    "# Calculate for all students\n",
    "results = []\n",
    "for idx, row in df_distance.iterrows():\n",
    "    student = row['Student']\n",
    "    point = np.array([row['Feature1'], row['Feature2']])\n",
    "    \n",
    "    euclidean = euclidean_distance(point, q)\n",
    "    manhattan = manhattan_distance(point, q)\n",
    "    \n",
    "    results.append({\n",
    "        'Student': student,\n",
    "        'Point': f\"[{point[0]}, {point[1]}]\",\n",
    "        'Euclidean Distance': round(euclidean, 3),\n",
    "        'Manhattan Distance': manhattan\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nDistance Calculations for All Students:\")\n",
    "print(df_results)\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cd29464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sklearn distance functions:\n",
      "  Student  Feature1  Feature2  Euclidean_sklearn  Manhattan_sklearn\n",
      "0      S1        70        80             11.180               15.0\n",
      "1      S2        60        90             25.000               35.0\n",
      "2      S3        85        60             14.142               20.0\n",
      "3      S4        78        76              6.708                9.0\n",
      "4      S5        62        65             13.928               18.0\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Using sklearn for distance calculations\n",
    "from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances\n",
    "\n",
    "# Prepare data\n",
    "X = df_distance[['Feature1', 'Feature2']].values\n",
    "q_reshaped = q.reshape(1, -1)\n",
    "\n",
    "# Calculate distances\n",
    "euclidean_dist = euclidean_distances(X, q_reshaped).flatten()\n",
    "manhattan_dist = manhattan_distances(X, q_reshaped).flatten()\n",
    "\n",
    "df_distance['Euclidean_sklearn'] = np.round(euclidean_dist, 3)\n",
    "df_distance['Manhattan_sklearn'] = manhattan_dist\n",
    "\n",
    "print(\"Using sklearn distance functions:\")\n",
    "print(df_distance)\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d93c934f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nearest Neighbors to Query Point q = [75, 70]:\n",
      "\n",
      "By Euclidean Distance: S4 with distance 6.708\n",
      "By Manhattan Distance: S4 with distance 9\n"
     ]
    }
   ],
   "source": [
    "# Find nearest neighbor\n",
    "nearest_euclidean = df_results.loc[df_results['Euclidean Distance'].idxmin()]\n",
    "nearest_manhattan = df_results.loc[df_results['Manhattan Distance'].idxmin()]\n",
    "\n",
    "print(\"\\nNearest Neighbors to Query Point q = [75, 70]:\")\n",
    "print(f\"\\nBy Euclidean Distance: {nearest_euclidean['Student']} with distance {nearest_euclidean['Euclidean Distance']}\")\n",
    "print(f\"By Manhattan Distance: {nearest_manhattan['Student']} with distance {nearest_manhattan['Manhattan Distance']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5a931",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Scaling Methods\n",
    "1. **Standardization (Z-score):** Centers data around 0 with std = 1. Good for normally distributed data.\n",
    "2. **Min-Max Scaling:** Scales data to [0, 1]. Sensitive to outliers.\n",
    "3. **Robust Scaling:** Uses median and IQR. Resistant to outliers.\n",
    "\n",
    "### Encoding Methods\n",
    "1. **One-Hot Encoding:** For nominal features (no order). Creates binary columns.\n",
    "2. **Ordinal Encoding:** For ordinal features (with order). Assigns numerical ranks.\n",
    "\n",
    "### Distance Measures\n",
    "1. **Euclidean Distance:** Straight line distance. Sensitive to large differences.\n",
    "2. **Manhattan Distance:** Sum of absolute differences. Used in grid-based problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
