{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "88b00676",
      "metadata": {
        "id": "88b00676"
      },
      "source": [
        "\n",
        "# Week 01 Assignment  \n",
        "## Data Quality, Evaluation, Scaling, and Encoding\n",
        "\n",
        "**Student name: Md.Atikur Rahaman**   \n",
        "\n",
        "This is a small assignment that connects topics from Module 1, 2, and 3.  \n",
        "You must complete it in this Colab notebook.\n",
        "\n",
        "You will need to use concepts that appeared in the videos:\n",
        "- Module 1 and 2: basic descriptive statistics, proportions, confusion matrix, accuracy, precision, recall\n",
        "- Module 3: standardization, min max scaling, nominal vs ordinal, one hot encoding, ordinal encoding, Euclidean and Manhattan distance\n",
        "\n",
        "Please do not use any extra libraries beyond `pandas`, `numpy`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b259ec4e",
      "metadata": {
        "id": "b259ec4e"
      },
      "source": [
        "\n",
        "---\n",
        "## 0. Setup and Dataset\n",
        "\n",
        "We will use a dataset that should have columns given below:\n",
        "\n",
        "- `user_id`  \n",
        "- `age`  \n",
        "- `monthly_income` (numeric)  \n",
        "- `daily_screen_time_min` (numeric)  \n",
        "- `daily_app_opens` (numeric)  \n",
        "- `true_label` and `pred_label` for a binary classification task (0 or 1)  \n",
        "- `satisfaction_level` (for example: `Low`, `Medium`, `High`)  \n",
        "- `city_type` (for example: `Urban`, `Suburban`, `Rural`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "59e47ae6",
      "metadata": {
        "id": "59e47ae6"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Imports\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4304549f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4304549f",
        "outputId": "a4b65fcf-90e3-4702-bae6-06acfab9bc9b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>age</th>\n",
              "      <th>monthly_income</th>\n",
              "      <th>daily_screen_time_min</th>\n",
              "      <th>daily_app_opens</th>\n",
              "      <th>true_label</th>\n",
              "      <th>pred_label</th>\n",
              "      <th>satisfaction_level</th>\n",
              "      <th>city_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>3734.19</td>\n",
              "      <td>109</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Suburban</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>49</td>\n",
              "      <td>2594.19</td>\n",
              "      <td>194</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Low</td>\n",
              "      <td>Urban</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>19</td>\n",
              "      <td>3550.47</td>\n",
              "      <td>146</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>High</td>\n",
              "      <td>Rural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>3821.18</td>\n",
              "      <td>287</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>High</td>\n",
              "      <td>Suburban</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>63</td>\n",
              "      <td>1750.84</td>\n",
              "      <td>66</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Suburban</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  age  monthly_income  daily_screen_time_min  daily_app_opens  \\\n",
              "0        1   43         3734.19                    109               48   \n",
              "1        2   49         2594.19                    194                7   \n",
              "2        3   19         3550.47                    146               36   \n",
              "3        4   19         3821.18                    287               14   \n",
              "4        5   63         1750.84                     66               46   \n",
              "\n",
              "   true_label  pred_label satisfaction_level city_type  \n",
              "0           0           0             Medium  Suburban  \n",
              "1           0           0                Low     Urban  \n",
              "2           1           0               High     Rural  \n",
              "3           1           0               High  Suburban  \n",
              "4           0           0             Medium  Suburban  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cell 2: Load the dataset (Already done for you)\n",
        "df = pd.read_csv(\"module123_data.csv\")\n",
        "\n",
        "# Show first few rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33e827a5",
      "metadata": {
        "id": "33e827a5"
      },
      "source": [
        "\n",
        "### 0.1 Check your dataset\n",
        "\n",
        "1. Confirm that the dataset loaded correctly.  \n",
        "2. Check that you have at least these columns:  \n",
        "   - numeric: `age`, `monthly_income`, `daily_screen_time_min`, `daily_app_opens`  \n",
        "   - labels: `true_label`, `pred_label`  \n",
        "   - categorical: `satisfaction_level`, `city_type`  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "740c5e00",
      "metadata": {
        "id": "740c5e00"
      },
      "source": [
        "\n",
        "---\n",
        "## Part A - Module 1 and 2 Review\n",
        "\n",
        "In this part you will do simple descriptive statistics and basic classification evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2315a46d",
      "metadata": {
        "id": "2315a46d"
      },
      "source": [
        "\n",
        "### Q1. Descriptive statistics on a numeric feature\n",
        "\n",
        "Choose one numeric column, for example `daily_screen_time_min`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fa6cb0d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "fa6cb0d2",
        "outputId": "95ae9e35-b1dc-43cb-afe5-a263b17b8458"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    100.000000\n",
              "mean     181.890000\n",
              "std       68.886951\n",
              "min       60.000000\n",
              "25%      122.000000\n",
              "50%      178.000000\n",
              "75%      243.750000\n",
              "max      299.000000\n",
              "Name: daily_screen_time_min, dtype: float64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Q1.1: Choose your numeric column here [We already write this ans]\n",
        "num_col = \"daily_screen_time_min\"\n",
        "\n",
        "df[num_col].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e71d94c",
      "metadata": {
        "id": "8e71d94c"
      },
      "source": [
        "> **Q1.2 Short answer: [Marks: 05]**  \n",
        "> Look at the count, mean, min, max, and standard deviation for your chosen column.  \n",
        "> In 2 to 3 sentences, comment on what you see.  \n",
        "> For example, does the max look very far from the mean, or does it look quite close?\n",
        "\n",
        "Write your answer here:\n",
        "\n",
        "> The average daily screen time is 181.89 minutes (about 3 hours). Most users' screen time is close to this average, with some variation shown by the standard deviation of 68.89 minutes. The minimum is 60 minutes and maximum is 299 minutes, which shows the data is spread out fairly evenly without any unusual extreme values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16ab91b6",
      "metadata": {
        "id": "16ab91b6"
      },
      "source": [
        "\n",
        "### Q2. Proportion of positive class\n",
        "\n",
        "Use the `true_label` column, where 1 means \"positive\" and 0 means \"negative\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "adcece78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adcece78",
        "outputId": "d28d8502-d9e0-49da-ec14-fe99989a4837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive count: 52\n",
            "Total samples: 100\n",
            "Proportion of positive class: 0.52\n"
          ]
        }
      ],
      "source": [
        "# Q2.1: Compute proportion of positive class [We already write this ans]\n",
        "label_col = \"true_label\"\n",
        "\n",
        "positive_count = (df[label_col] == 1).sum()\n",
        "total_count = df.shape[0]\n",
        "positive_proportion = positive_count / total_count\n",
        "\n",
        "print(\"Positive count:\", positive_count)\n",
        "print(\"Total samples:\", total_count)\n",
        "print(\"Proportion of positive class:\", positive_proportion)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c065b4b4",
      "metadata": {
        "id": "c065b4b4"
      },
      "source": [
        "> **Q2.2 Short answer: [5 marks]**  \n",
        "> In 1 to 2 sentences, explain what this proportion tells you about your dataset.  \n",
        "> For example, is the dataset balanced between 0 and 1, or is one class much more common?\n",
        "\n",
        "Write your answer here:\n",
        "\n",
        "> The dataset is well-balanced because 52% of samples are positive class and 48% are negative class. This is good for training models because both classes have almost equal representation, which helps the model learn both classes equally well."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06ff684b",
      "metadata": {
        "id": "06ff684b"
      },
      "source": [
        "\n",
        "### Q3. Confusion matrix and basic metrics\n",
        "\n",
        "For this question, use:\n",
        "- `true_label` as the actual label  \n",
        "- `pred_label` as the model prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e075cdf0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e075cdf0",
        "outputId": "7fa4ca0f-d68e-42e6-cd3d-e3c486583cac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TP: 28\n",
            "TN: 27\n",
            "FP: 21\n",
            "FN: 24\n"
          ]
        }
      ],
      "source": [
        "# Q3.1: Manually compute TP, TN, FP, FN [We already write this ans]\n",
        "true_col = \"true_label\"\n",
        "pred_col = \"pred_label\"\n",
        "\n",
        "tp = ((df[true_col] == 1) & (df[pred_col] == 1)).sum()\n",
        "tn = ((df[true_col] == 0) & (df[pred_col] == 0)).sum()\n",
        "fp = ((df[true_col] == 0) & (df[pred_col] == 1)).sum()\n",
        "fn = ((df[true_col] == 1) & (df[pred_col] == 0)).sum()\n",
        "\n",
        "print(\"TP:\", tp)\n",
        "print(\"TN:\", tn)\n",
        "print(\"FP:\", fp)\n",
        "print(\"FN:\", fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8857988e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8857988e",
        "outputId": "218b9bb4-2631-4049-dc19-aa9d800776d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.55\n",
            "Precision: 0.5714285714285714\n",
            "Recall: 0.5384615384615384\n"
          ]
        }
      ],
      "source": [
        "# Q3.2: Compute accuracy, precision, recall [We already write this ans]\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
        "\n",
        "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0937d45c",
      "metadata": {
        "id": "0937d45c"
      },
      "source": [
        "> **Q3.3 Short answer: [10 marks]**  \n",
        "> In 3 to 4 sentences, briefly comment on the model using these three metrics.  \n",
        "> For example, is the model catching most positives (high recall) or being careful when it predicts positive (high precision)?\n",
        "\n",
        "Write your answer here:\n",
        "\n",
        "> The model has 55% accuracy, which means it is only slightly better than guessing randomly. The precision is 57%, meaning when the model predicts positive, it is correct about 57% of the time. The recall is 54%, which means the model catches only 54% of all actual positive cases and misses 46% of them. Overall, this model needs more improvement because it makes many mistakes in both directions (21 false positives and 24 false negatives)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f56c651d",
      "metadata": {
        "id": "f56c651d"
      },
      "source": [
        "\n",
        "---\n",
        "## Part B - Module 3: Scaling and Encoding\n",
        "\n",
        "Now we will pick a few features and apply scaling and encoding.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b0e548b",
      "metadata": {
        "id": "8b0e548b"
      },
      "source": [
        "\n",
        "### Q4. Standardization and Min max scaling\n",
        "\n",
        "Use one numeric column, `monthly_income`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e8f0c82f",
      "metadata": {
        "id": "e8f0c82f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected column: monthly_income\n",
            "\n",
            "Original values (first 5):\n",
            "0    3734.19\n",
            "1    2594.19\n",
            "2    3550.47\n",
            "3    3821.18\n",
            "4    1750.84\n",
            "Name: monthly_income, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Q4.1: Choose the numeric column [2 marks]\n",
        "income_col = \"monthly_income\"\n",
        "print(f\"Selected column: {income_col}\")\n",
        "print(f\"\\nOriginal values (first 5):\")\n",
        "print(df[income_col].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fba23640",
      "metadata": {
        "id": "fba23640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean: 2885.75\n",
            "Std: 898.12\n",
            "\n",
            "Standardized values (first 5):\n",
            "0    0.944685\n",
            "1   -0.324626\n",
            "2    0.740126\n",
            "3    1.041542\n",
            "4   -1.263639\n",
            "Name: income_std, dtype: float64\n",
            "\n",
            "Standardized range: [-2.10, 2.41]\n"
          ]
        }
      ],
      "source": [
        "# Q4.2: Standardization with z-score [10 marks]\n",
        "# Calculate mean and standard deviation\n",
        "mean_income = df[income_col].mean()\n",
        "std_income = df[income_col].std()\n",
        "\n",
        "# Apply z-score standardization: (x - mean) / std\n",
        "df['income_std'] = (df[income_col] - mean_income) / std_income\n",
        "\n",
        "print(f\"Mean: {mean_income:.2f}\")\n",
        "print(f\"Std: {std_income:.2f}\")\n",
        "print(f\"\\nStandardized values (first 5):\")\n",
        "print(df['income_std'].head())\n",
        "print(f\"\\nStandardized range: [{df['income_std'].min():.2f}, {df['income_std'].max():.2f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "12ec9ab7",
      "metadata": {
        "id": "12ec9ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min: 1000.00\n",
            "Max: 5049.40\n",
            "\n",
            "Min-Max scaled values (first 5):\n",
            "0    0.675209\n",
            "1    0.393685\n",
            "2    0.629839\n",
            "3    0.696691\n",
            "4    0.185420\n",
            "Name: income_minmax, dtype: float64\n",
            "\n",
            "Min-Max range: [0.00, 1.00]\n"
          ]
        }
      ],
      "source": [
        "# Q4.3: Min max scaling implementation [10 marks]\n",
        "# Calculate min and max\n",
        "min_income = df[income_col].min()\n",
        "max_income = df[income_col].max()\n",
        "\n",
        "# Apply min-max scaling: (x - min) / (max - min)\n",
        "df['income_minmax'] = (df[income_col] - min_income) / (max_income - min_income)\n",
        "\n",
        "print(f\"Min: {min_income:.2f}\")\n",
        "print(f\"Max: {max_income:.2f}\")\n",
        "print(f\"\\nMin-Max scaled values (first 5):\")\n",
        "print(df['income_minmax'].head())\n",
        "print(f\"\\nMin-Max range: [{df['income_minmax'].min():.2f}, {df['income_minmax'].max():.2f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a21a7545",
      "metadata": {
        "id": "a21a7545"
      },
      "source": [
        "> **Q4.4 Short answer: [3 marks]**  \n",
        "> Compare the standardized and min max scaled columns in 2 to 3 sentences.  \n",
        "> Mention what kind of range each one uses and how the numbers look.\n",
        "\n",
        "Write your answer here:\n",
        "\n",
        "> The standardized column has values centered around 0, with most values between -3 and +3. Negative numbers mean below average income, and positive numbers mean above average income. The min-max scaled column changes all values to be between 0 and 1, where 0 is the smallest income and 1 is the largest income. We use standardization when we want to know how far a value is from the average, and we use min-max scaling when we need all features to be on the same scale from 0 to 1."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "057ed4dd",
      "metadata": {
        "id": "057ed4dd"
      },
      "source": [
        "\n",
        "### Q5. One hot and ordinal encoding\n",
        "\n",
        "We will use:\n",
        "- `city_type` as a nominal feature  \n",
        "- `satisfaction_level` as an ordinal feature with order `Low` < `Medium` < `High`  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f3f9a90c",
      "metadata": {
        "id": "f3f9a90c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-hot encoded city_type:\n",
            "   city_Rural  city_Suburban  city_Urban\n",
            "0       False           True       False\n",
            "1       False          False        True\n",
            "2        True          False       False\n",
            "3       False           True       False\n",
            "4       False           True       False\n",
            "5        True          False       False\n",
            "6        True          False       False\n",
            "7        True          False       False\n",
            "8       False          False        True\n",
            "9        True          False       False\n",
            "\n",
            "Original column vs encoded columns:\n",
            "  city_type  city_Rural  city_Suburban  city_Urban\n",
            "0  Suburban       False           True       False\n",
            "1     Urban       False          False        True\n",
            "2     Rural        True          False       False\n",
            "3  Suburban       False           True       False\n",
            "4  Suburban       False           True       False\n",
            "5     Rural        True          False       False\n",
            "6     Rural        True          False       False\n",
            "7     Rural        True          False       False\n",
            "8     Urban       False          False        True\n",
            "9     Rural        True          False       False\n"
          ]
        }
      ],
      "source": [
        "# Q5.1: One hot encoding for city_type using pandas [10 marks]\n",
        "# Use pd.get_dummies() for one-hot encoding\n",
        "city_encoded = pd.get_dummies(df['city_type'], prefix='city')\n",
        "\n",
        "print(\"One-hot encoded city_type:\")\n",
        "print(city_encoded.head(10))\n",
        "print(f\"\\nOriginal column vs encoded columns:\")\n",
        "print(pd.concat([df['city_type'].head(10), city_encoded.head(10)], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "194098d0",
      "metadata": {
        "id": "194098d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataframe with one-hot encoded columns:\n",
            "  city_type  city_Rural  city_Suburban  city_Urban\n",
            "0  Suburban       False           True       False\n",
            "1     Urban       False          False        True\n",
            "2     Rural        True          False       False\n",
            "3  Suburban       False           True       False\n",
            "4  Suburban       False           True       False\n",
            "5     Rural        True          False       False\n",
            "6     Rural        True          False       False\n",
            "7     Rural        True          False       False\n",
            "8     Urban       False          False        True\n",
            "9     Rural        True          False       False\n"
          ]
        }
      ],
      "source": [
        "# Q5.2: Attach one hot encoded columns to df [5 marks]\n",
        "# Concatenate the one-hot encoded columns to the original dataframe\n",
        "df = pd.concat([df, city_encoded], axis=1)\n",
        "\n",
        "print(\"Dataframe with one-hot encoded columns:\")\n",
        "print(df[['city_type', 'city_Rural', 'city_Suburban', 'city_Urban']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "71e83a16",
      "metadata": {
        "id": "71e83a16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ordinal encoding for satisfaction_level:\n",
            "\n",
            "Mapping: {'Low': 0, 'Medium': 1, 'High': 2}\n",
            "\n",
            "Original vs Encoded:\n",
            "  satisfaction_level  satisfaction_encoded\n",
            "0             Medium                     1\n",
            "1                Low                     0\n",
            "2               High                     2\n",
            "3               High                     2\n",
            "4             Medium                     1\n",
            "5                Low                     0\n",
            "6                Low                     0\n",
            "7               High                     2\n",
            "8               High                     2\n",
            "9             Medium                     1\n",
            "\n",
            "Value counts:\n",
            "satisfaction_level  satisfaction_encoded\n",
            "High                2                       29\n",
            "Low                 0                       35\n",
            "Medium              1                       36\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Q5.3: Ordinal encoding for satisfaction_level [10 marks]\n",
        "# Define the ordinal mapping: Low < Medium < High\n",
        "ordinal_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
        "\n",
        "# Apply the mapping\n",
        "df['satisfaction_encoded'] = df['satisfaction_level'].map(ordinal_mapping)\n",
        "\n",
        "print(\"Ordinal encoding for satisfaction_level:\")\n",
        "print(f\"\\nMapping: {ordinal_mapping}\")\n",
        "print(f\"\\nOriginal vs Encoded:\")\n",
        "print(df[['satisfaction_level', 'satisfaction_encoded']].head(10))\n",
        "print(f\"\\nValue counts:\")\n",
        "print(df[['satisfaction_level', 'satisfaction_encoded']].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a969ca2b",
      "metadata": {
        "id": "a969ca2b"
      },
      "source": [
        "> **Q5.4 Short answer: [5 marks]**  \n",
        "> In 2 to 3 sentences, explain why one hot encoding is suitable for `city_type`  \n",
        "> and why ordinal encoding is suitable for `satisfaction_level`.\n",
        "\n",
        "Write your answer here:\n",
        "\n",
        "> One-hot encoding is good for `city_type` because Urban, Suburban, and Rural are just different categories with no ranking or order. One-hot encoding creates separate columns for each city type so the model doesn't think one city is \"bigger\" or \"better\" than another. Ordinal encoding is good for `satisfaction_level` because Low, Medium, and High have a clear order (Low < Medium < High), and encoding them as 0, 1, 2 helps the model understand that High is greater than Medium, which is greater than Low."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9d76c20",
      "metadata": {
        "id": "d9d76c20"
      },
      "source": [
        "\n",
        "---\n",
        "## Part C - Module 3: Distances between users\n",
        "\n",
        "For this small part we will work with vectors based on scaled numeric features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed773931",
      "metadata": {
        "id": "ed773931"
      },
      "source": [
        "\n",
        "### Q6. Euclidean and Manhattan distance\n",
        "\n",
        "Build 2D vectors for user 0 and user 1 using:\n",
        "- `income_std`  \n",
        "- `daily_app_opens` (or its min max scaled version if you prefer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e52ab645",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e52ab645",
        "outputId": "bc7c8d9d-b1c5-4514-cad7-7e5a9535fb25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "v1: [3734.19 48]\n",
            "v2: [2594.19 7]\n"
          ]
        }
      ],
      "source": [
        "# Q6.1: Build 2D vectors for first two users [We already write this ans]\n",
        "vec_cols = [\"monthly_income\", \"daily_app_opens\"]\n",
        "\n",
        "v1 = df.loc[0, vec_cols].values\n",
        "v2 = df.loc[1, vec_cols].values\n",
        "\n",
        "print(\"v1:\", v1)\n",
        "print(\"v2:\", v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d887c5b8",
      "metadata": {
        "id": "d887c5b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector 1: [3734.19 48]\n",
            "Vector 2: [2594.19 7]\n",
            "\n",
            "Euclidean distance: 1140.74\n",
            "\n",
            "Calculation: sqrt((3734.19-2594.19)^2 + (48-7)^2)\n",
            "           = sqrt(1299600.00 + 1681.00)\n",
            "           = sqrt(1301281.00) = 1140.74\n"
          ]
        }
      ],
      "source": [
        "# Q6.2: Euclidean distance computation [5 marks]\n",
        "# Euclidean distance formula: sqrt(sum((x_i - y_i)^2))\n",
        "euclidean_dist = np.sqrt(np.sum((v1 - v2) ** 2))\n",
        "\n",
        "print(f\"Vector 1: {v1}\")\n",
        "print(f\"Vector 2: {v2}\")\n",
        "print(f\"\\nEuclidean distance: {euclidean_dist:.2f}\")\n",
        "print(f\"\\nCalculation: sqrt((3734.19-2594.19)^2 + (48-7)^2)\")\n",
        "print(f\"           = sqrt({(v1[0]-v2[0])**2:.2f} + {(v1[1]-v2[1])**2:.2f})\")\n",
        "print(f\"           = sqrt({np.sum((v1-v2)**2):.2f}) = {euclidean_dist:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c7600334",
      "metadata": {
        "id": "c7600334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector 1: [3734.19 48]\n",
            "Vector 2: [2594.19 7]\n",
            "\n",
            "Manhattan distance: 1181.00\n",
            "\n",
            "Calculation: |3734.19-2594.19| + |48-7|\n",
            "           = 1140.00 + 41.00\n",
            "           = 1181.00\n"
          ]
        }
      ],
      "source": [
        "# Q6.3: Manhattan distance computation [5 marks]\n",
        "# Manhattan distance formula: sum(|x_i - y_i|)\n",
        "manhattan_dist = np.sum(np.abs(v1 - v2))\n",
        "\n",
        "print(f\"Vector 1: {v1}\")\n",
        "print(f\"Vector 2: {v2}\")\n",
        "print(f\"\\nManhattan distance: {manhattan_dist:.2f}\")\n",
        "print(f\"\\nCalculation: |3734.19-2594.19| + |48-7|\")\n",
        "print(f\"           = {abs(v1[0]-v2[0]):.2f} + {abs(v1[1]-v2[1]):.2f}\")\n",
        "print(f\"           = {manhattan_dist:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1cdf3e1",
      "metadata": {
        "id": "c1cdf3e1"
      },
      "source": [
        "> **Q6.4 Short answer: [5 marks]**  \n",
        "> Which one is larger in your result, Euclidean or Manhattan distance  \n",
        "> and why does that usually happen based on their formulas?\n",
        "\n",
        "Write your answer here:\n",
        "\n",
        "> Manhattan distance (1181.00) is larger than Euclidean distance (1140.74) in this result. This happens because Manhattan distance adds up all the differences directly (1140 + 41 = 1181), while Euclidean distance takes the square root after adding squared differences (√(1140² + 41²) = 1140.74). Taking the square root makes the final number smaller. Manhattan distance is usually larger, especially when one feature has much bigger differences than others, like income in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb70404e",
      "metadata": {
        "id": "cb70404e"
      },
      "source": [
        "---\n",
        "## Final Reflection [10 marks]\n",
        "\n",
        "> In 4 to 6 sentences, describe how the three modules connect in this assignment.  \n",
        "> Mention:\n",
        "> - One idea from Module 1 or 2 that you used  \n",
        "> - One idea from Module 3 that you used  \n",
        "> - How these ideas together help you understand a dataset more deeply\n",
        "\n",
        "Write your reflection here:\n",
        "\n",
        "> In this assignment, I learned how different modules work together to analyze data and build machine learning models. From Module 1 and 2, I used descriptive statistics like mean and standard deviation to understand the data, and I used confusion matrix with precision and recall to check how well the model performs. From Module 3, I learned how to prepare data for machine learning by using standardization and min-max scaling to make numbers comparable, and using one-hot encoding and ordinal encoding to convert categories into numbers. These techniques work together as a complete process: first I explore the data to understand it, then I transform the data to make it ready for models, and finally I evaluate the model to see if it works well. The distance calculations showed me why scaling is important - without scaling, features with big numbers (like income) will dominate the calculations over features with small numbers (like app opens). This complete approach helps me understand both what the data means and how to prepare it properly for machine learning."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
